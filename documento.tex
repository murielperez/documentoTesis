\documentclass[letterpaper,12pt]{book}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\title{Clasificación de Series de Tiempo Astronómicas}
\author{Muriel Pérez\\ 201011755}
\begin{document}
\maketitle
\tableofcontents 
\chapter{Introducción}

Con los avances en técnicas de observación astronómica que han sucedido en los últimos años, hay grandes cantidades de datos disponibles. Estudios como la misión Kepler de la \textit{National Aeronautics and Space Administration} (NASA), o el \textit{VISTA Variables in the Via Lactea} (VVV) del \textit{European Southern Observatory} (ESO) tienen como productos gran cantidad de curvas  de luz \footnote{\label{nota:curvasDeLuz} La curva de luz de una estrella es el resultado de medir su magnitud como función del tiempo. La magnitud de una estrella es el flujo de energía observado en una parte del espectro electromagnético en escala logarítmica (ver el capítulo 4 de \cite{karttunen_fundamental_2007}).}(necesito información sobre más estudios y dar números sobre la cantidad de estrellas observadas) de alta calidad.

Para que estos datos sean útiles en la comunidad científica es necesario clasificarlos y extraer sus características. Si se quiere lograr esto en poco tiempo, es necesario utilizar técnicas de minería de datos debido a los volúmenes que deben ser procesados. (este párrafo necesita más palabras)

En este trabajo abordamos el problema de clasificar curvas de luz de estrellas variables por su tipo de variabilidad \footnote{Las estrellas variables son estrellas cuya magnitud cambia en el tiempo (ver nota \ref{nota:curvasDeLuz}). Pueden ser periódicas o no periódicas y se pueden clasificar como pulsantes, eruptivas o variables eclipsantes aunque existen subclases de variabilidad estelar. Una estrella puede ser clasificada en estas subclases conociendo su curva de luz (ver el capítulo 13 de \cite{karttunen_fundamental_2007}).} como un problema de aprendizaje supervisado \footnote{Se busca, a partir de los datos, inferir una regla que le asigne a cada curva de luz un tipo de variabilidad. Esta regla debe poder aplicarse a curvas de luz que estén fuera de la muestra y la probabilidad de errror es estimada utilizando la muestra original. (ver capítulo \ref{cap:problemaAprendizaje})}. Para esto utilizamos una parte de los resultados de la tercera fase del \textit{Optical Gravitational Lensing Experiment} (OGLE III) que contiene curvas de luz  de estrellas previamente clasificadas en seis tipos de variabilidad estelar y curvas de luz de estrellas candidatas a ser clasificadas como Be (¿De dónde vienen estos datos de las Be?)(ver capítulo \ref{cap:losDatos}) (¿Por qué elegimos este conjunto de datos?) (ver cuadro \ref{cuadro:datosUsados}). Estas curvas de luz fueron clasificadas por personas y tomaremos esta clasificación como verdadera.

\begin{table}
  \centering
  \begin{tabular}{rr}
    \hline
    \hline
    Tipo de variabilidad y origen & \shortstack{Número \\de Objetos}\\
    \hline
    \hline
    RR Lyrae - Bulbo Galáctico\cite{soszynski_optical_2011-2} & 16836\\
    RR Lyrae - Nube Menor de Magallanes \cite{soszynski_optical_2010}& 2475\\
    RR Lyrae - Nube Mayor de Magallanes \cite{soszynski_optical_2009-1}& 24906\\
    \hline
    Cefeidas - Bulbo Galáctico \cite{soszynski_optical_2011}& 32\\%El título del paper es classical and type2 cepheids
    Cefeidas - Nube Menor de Magallanes \cite{soszynski_optical_2010-2}& 4630\\
    Cefeidas - Nube Mayor de Magallanes \cite{soszynski_optical_2008-1}& 3361\\
    \hline
    Variables de Largo Periodo - Bulbo Galáctico \cite{soszynski_optical_2013-1}& 232406\\
    Variables de Largo Periodo - Nube Menor de Magallanes \cite{soszynski_optical_2011-1}& 19384\\
    Variables de Largo Periodo - Nube Mayor de Magallanes \cite{soszynski_optical_2009}& 91995\\
    \hline
    Binaria Eclipsante - Nube Menor de Magallanes \cite{pawlak_eclipsing_2013}& 6138\\
    Binaria Eclipsante - Nube Mayor de Magallanes \cite{graczyk_optical_2011}& 26121\\
    \hline
    $\delta$-Scuti - Nube Mayor de Magallanes\cite{poleski_optical_2010} & 2786\\
    \hline
    Cefeidas Tipo II - Bulbo Galáctico \cite{soszynski_optical_2013}& 335\\
    Cefeidas Tipo II - Nube Menor de Magallanes \cite{soszynski_optical_2010-1}& 43\\
    Cefeidas Tiplo II - Nube Mayor de Magallanes \cite{soszynski_optical_2008}& 197\\
    \hline
    BeSC -  Vía Láctea (cita!) & 475\\
    \hline
    \hline 
  \end{tabular}
  \caption{Conjunto de datos utilizados (faltan las citas de los catálogos)}
  \label{cuadro:datosUsados}
\end{table}

Para abordar el problema de clasificación adoptamos el siguiente punto de vista. Cada curva de luz $c_i = \{(t_{n}^{i}, m_{n}^{i})\}_{n}$ es una sucesión de parejas donde la primera es el tiempo y la segunda es la magnitud medida en ese instante.  Debido a limitaciones en el tiempo de observación, fallas técnicas, periodos de matenimiento de los instrumentos utilizados y el hecho de que no todas las regiones del cielo son observables durante todo el año y solo se puede observar una región limitada en cada oportunidad, las curvas de luz no constan del mismo número de observaciones y éstas no son hechas en intervalos regulares ($t_{k} - t_{k+1}$ no es constante). Una forma de hacer frente a esto es asignarle a cada curva de luz $c_i$ un vector de atributos $\vec{x_{i}} = \vec{x_{i}}(c_i)\in\mathbb{R}^{n}$ calculados a partir de de $c_i$ (ver sección \ref{sec:atributos}) que intenten describir los tipos de variabilidad. Como los elementos de la muestra han sido clasificados previamente, le asignamos a cada curva de luz $c_i$ una etiqueta $j_i\in J=\{\text{RR Lyr}, \dots, \text{BeSC}\}$ (ver tabla \ref{cuadro:datosUsados}) que corresponde al tipo de variabilidad estelar de la estrella observada.  Dicha etiqueta, a su vez, es heredada por el vector de atributos $\vec{x}_i$.

Si nuestra elección de atributos es acertada, podremos utilizar la representación de las curvas de luz en el espacio de atributos para realizar la clasificación, esto es, existirá una función $g:\mathbb{R}^n\rightarrow J$ que, de alcanzar la mejor tasa de clasificación correcta posible para esos atributos, le asigna a cada curva de luz el tipo de variabilidad correcto con probabilidad alta (ver capítulo \ref{cap:problemaAprendizaje}). Puede suceder que, si los atributos no caracterizan los diferentes tipos de variabilidad, incluso utilizando el mejor clasificador posible (la mejor función $g$) no sea posible alcanzar errores de clasificación bajos. De esto se sigue que la elección de atributos es crucial para lograr una buena clasificación. La elección de los atributos utilizados se discute en la sección \ref{sec:atributos}.

El siguiente problema será el de inferir de los datos una función $\hat{g}:\mathbb{R}^n\rightarrow J$ que se aproxime tanto como sea posible a la mejor regla posible en cuanto a que maximice la probabilidad de clasificación correcta. Para encontrar esta regla existen diferentes aproximaciones y algorítmos que permiten la división del espacio de atributos en zonas a cada una de las cuales se le asigna un tipo de variabilidad. En la práctica no se conoce la mejor regla posible porque esto requeriría el conocimiento de la distribución exacta de los atributos (ver capítulo \ref{cap:problemaAprendizaje}). Tampoco se conoce el mínimo error de clasificación posible por lo que, para la selección del mejor clasificador entre los posibles, se utilizan estimaciones del error de clasificación que utilizan la muestra disponible, en este caso validación cruzada (ver sección \ref{sec:estimacionError}).En el capítulo \ref{cap:aprendizaje} utilizamos k vecinos más cercanos, arboles de clasificación y regresión; y maquinas de soporte vectorial para inferir la función $\hat{g}$. Asímismo analizamos los estimados de la probabilidad de error al usar cada algorítmo y comentamos las ventajas comparativas de cada uno. Estos tres métodos son muy diferentes en su naturaleza, fueron elegidos porque han mostrado ser efectivos en gran variedad de aplicaciones y por su carácter no paramétrico y no lineal. 

Así la clasificación de una curva de luz correspondiente a una estrella cuyo tipo de variabilidad es desconocido será un proceso de dos pasos. El primero será la extracción de los atributos. El segundo paso será la clasificación basada en los atributos utilizando la función $\hat{g}$ que fue encontrada con ayuda de la muestra disponible. Esta clasificación será correcta con cierta probabilidad, estimada con validación cruzada.

Este documento está organizado de la siguiente manera. En el capítulo \ref{cap:losDatos} damos un análisis descriptivo del conjunto de datos que consideramos y discutimos la elección de los atributos para realizar la clasificación. En el capítulo \ref{cap:problemaAprendizaje} discutimos brevemente el problema de clasificación en general, describimos el mejor clasificador posible (el clasificador de Bayes), discutimos la imposibilidad de utilizarlo en la mayoría de aplicaciones complejas y describimos el método que usamos para estimar la probabilidad de error de los clasificadores. En el capítulo \ref{cap:aprendizaje} describimos los métodos de clasificación utilizados, damos los estimados del error de clasificación y comparamos los resultados con otros valores dados en la literatura.

\chapter{El conjunto de Datos de OGLE III\label{cap:losDatos}}
\section{Descripción de los Datos}
\section{Atributos Seleccionados \label{sec:atributos}}

\chapter{El Problema del Aprendizaje\label{cap:problemaAprendizaje}}

A cada curva de luz $c_{i} = \{(t_{n}^{i},m_{n}^{i} )\}_{n}$ le asignamos un vector de atributos $\vec{x}_{i}$ (ver sección \ref{sec:atributos}) y con estos esperamos construir una regla de desición $\hat{g}:\mathbb{R}^n\rightarrow J= \{\text{RR Lyr}, \dots, \text{BeSC}\}$(ver capítulo \ref{cap:aprendizaje}) que sea la mejor posible. ¿Pero qé significa que una regla sea la mejor posible? 

\section{Estimación del Error de Clasificación}\label{sec:estimacionError}

\chapter{Aprendizaje Supervisado\label{cap:aprendizaje}}

\section{K Vecinos Más cercanos}

\section{Árboles de Clasificación y Regresión}

\section{Bosques Aleatorios}%Posiblemente


\bibliographystyle{plain}
\bibliography{tesisMatematicas}

\end{document}